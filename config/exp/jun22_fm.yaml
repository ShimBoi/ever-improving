# @package _global_

# help with sweepers
# https://stackoverflow.com/questions/70619014/specify-hydra-multirun-sweeps-in-a-config-file
# https://github.com/facebookresearch/hydra/issues/1376#issuecomment-1011704938

defaults:
# - /launcher: base
  - override /algo: ppo
  - override /buffer: base # no HER for now!
  - override /env/foundation: rtx

  - _self_

log_dir: ${callback.log_path}
sweep_id: "jun22_fm"

train: 
  n_steps: ${r_toint:1e6} # 1M
  use_zero_init: True # cant zero without foundation model

algo:
  batch_size: 256
  # warmup_zero_action: False # gaussian
  ent_coef: 0.02
  learning_rate: 3e-4
  target_kl: 0.02

env:
  goal: 
    use: False
  use_original_space: False # ppo doesnt support this rn
  reach: False
  reward: sparse
  seed:
    force: True
    seeds: 10

  residual_scale: 0.5
  action_mask_dims: 
    - -1

  n_envs: 1

hydra:
  run:
    dir: ${log_dir}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${log_dir}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.override_dirname}

  mode: MULTIRUN # needed or else -m flag
  sweeper:
    params:
      env.residual_scale: 0.5 # 0.1
      env/obs_mode: oracle
