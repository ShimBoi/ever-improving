# @package _global_

# to see if sac improves when the critic learns from fm and rp together

# help with sweepers
# https://stackoverflow.com/questions/70619014/specify-hydra-multirun-sweeps-in-a-config-file
# https://github.com/facebookresearch/hydra/issues/1376#issuecomment-1011704938

defaults:
  - override /algo: sac
  - override /buffer: base
  - override /env/foundation: dont
  - _self_

env:
  goal:
    use: False
  seed:
    force: True
  reward: reach

  obs_keys: # anything besides the expected image
  - agent_qpos-sin
  - agent_qpos-cos
  - agent_qvel
  - eef-pose
  - obj-wrt-eef
  - obj-pose

sweep_id: "jun13_simple_grasp"

train: 
  n_steps: ${r_toint:3e5} # 30K
  use_zero_init: False

algo:
  batch_size: 8192 # downscale 7 by default
  learning_starts: ${r_toint:1e4} # 10k
  buffer_size: ${r_toint:1e6}

  learning_rate: ${r_tofloat:3e-4}
  ent_coef: auto_0.5
  target_entropy: -7.0 # from SAC applications

  warmup_zero_action: False

log_dir: ${callback.log_path}
hydra:
  run:
    dir: ${log_dir}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${log_dir}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.override_dirname}
